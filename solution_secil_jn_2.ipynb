{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Start.\n",
      " - Read Train Data.\n",
      " - Make Validation Set.\n",
      " - Read Test Data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import libraries\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import division\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def logloss_mc(y_true, y_prob, epsilon=1e-15): #    Multiclass logloss\n",
    "    \n",
    "    # normalize\n",
    "    y_prob = y_prob / y_prob.sum(axis=1).reshape(-1, 1)\n",
    "    y_prob = np.maximum(epsilon, y_prob)\n",
    "    y_prob = np.minimum(1 - epsilon, y_prob)\n",
    "    # get probabilities\n",
    "    y = [y_prob[i, j] for (i, j) in enumerate(y_true)]\n",
    "    ll = - np.mean(np.log(y))\n",
    "    return ll\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    print(\" - Start.\")\n",
    "    \n",
    "    testFile=\"task\\\\task\\\\testData.csv\"\n",
    "    trainFile=\"task\\\\task\\\\trainData.csv\"\n",
    "    outFile=\"solution_swc.csv\"\n",
    "\n",
    "    #read train data\n",
    "    print(\" - Read Train Data.\")\n",
    "    df_train = pd.read_csv(trainFile)\n",
    "    \n",
    "    #df_train.reset_index(level=0, inplace=True)\n",
    "    \n",
    "    X_TRN = df_train.values.copy()\n",
    "    np.savetxt(r\"c1.csv\",X_TRN,delimiter=',')\n",
    "    np.random.shuffle(X_TRN)\n",
    "    np.savetxt(r\"c2.csv\",X_TRN,delimiter=',')\n",
    "    np.savetxt(r\"c3.csv\",X_TRN[:, :-1],delimiter=',')\n",
    "    np.savetxt(r\"c4.csv\",X_TRN[:, -1],delimiter=',')\n",
    "    \n",
    "    #standardize\n",
    "    X_std = StandardScaler().fit_transform(X_TRN[:, :-1])\n",
    "    \n",
    "    \n",
    "    #make validation set\n",
    "    print(\" - Make Validation Set.\")    \n",
    "    train_size=0.8\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_std, X_TRN[:, -1], train_size=train_size,)\n",
    "\n",
    "    #read test data\n",
    "    print(\" - Read Test Data.\")     \n",
    "    df_test = pd.read_csv(testFile)\n",
    "    #df_test.reset_index(level=0, inplace=True)\n",
    "    X_t = df_test.values.copy()\n",
    "    X_TST = StandardScaler().fit_transform(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Running xgboost.\n",
      "[0]\tvalidation_0-mlogloss:1.95339\tvalidation_1-mlogloss:1.95731\n",
      "[1]\tvalidation_0-mlogloss:1.78367\tvalidation_1-mlogloss:1.79242\n",
      "[2]\tvalidation_0-mlogloss:1.64394\tvalidation_1-mlogloss:1.65693\n",
      "[3]\tvalidation_0-mlogloss:1.53493\tvalidation_1-mlogloss:1.55074\n",
      "[4]\tvalidation_0-mlogloss:1.44108\tvalidation_1-mlogloss:1.46042\n",
      "[5]\tvalidation_0-mlogloss:1.35712\tvalidation_1-mlogloss:1.37909\n",
      "[6]\tvalidation_0-mlogloss:1.28639\tvalidation_1-mlogloss:1.31055\n",
      "[7]\tvalidation_0-mlogloss:1.22572\tvalidation_1-mlogloss:1.25228\n",
      "[8]\tvalidation_0-mlogloss:1.16792\tvalidation_1-mlogloss:1.19689\n",
      "[9]\tvalidation_0-mlogloss:1.11727\tvalidation_1-mlogloss:1.14837\n",
      "[10]\tvalidation_0-mlogloss:1.06902\tvalidation_1-mlogloss:1.10262\n",
      "[11]\tvalidation_0-mlogloss:1.02601\tvalidation_1-mlogloss:1.06191\n",
      "[12]\tvalidation_0-mlogloss:0.986953\tvalidation_1-mlogloss:1.02495\n",
      "[13]\tvalidation_0-mlogloss:0.952257\tvalidation_1-mlogloss:0.992293\n",
      "[14]\tvalidation_0-mlogloss:0.920408\tvalidation_1-mlogloss:0.962217\n",
      "[15]\tvalidation_0-mlogloss:0.890029\tvalidation_1-mlogloss:0.933588\n",
      "[16]\tvalidation_0-mlogloss:0.86165\tvalidation_1-mlogloss:0.907531\n",
      "[17]\tvalidation_0-mlogloss:0.836597\tvalidation_1-mlogloss:0.88394\n",
      "[18]\tvalidation_0-mlogloss:0.813098\tvalidation_1-mlogloss:0.862068\n",
      "[19]\tvalidation_0-mlogloss:0.791494\tvalidation_1-mlogloss:0.842142\n",
      "[20]\tvalidation_0-mlogloss:0.771312\tvalidation_1-mlogloss:0.823948\n",
      "[21]\tvalidation_0-mlogloss:0.752492\tvalidation_1-mlogloss:0.806942\n",
      "[22]\tvalidation_0-mlogloss:0.734665\tvalidation_1-mlogloss:0.790575\n",
      "[23]\tvalidation_0-mlogloss:0.717844\tvalidation_1-mlogloss:0.775615\n",
      "[24]\tvalidation_0-mlogloss:0.701822\tvalidation_1-mlogloss:0.76156\n",
      "[25]\tvalidation_0-mlogloss:0.68736\tvalidation_1-mlogloss:0.748662\n",
      "[26]\tvalidation_0-mlogloss:0.673745\tvalidation_1-mlogloss:0.736538\n",
      "[27]\tvalidation_0-mlogloss:0.660906\tvalidation_1-mlogloss:0.725208\n",
      "[28]\tvalidation_0-mlogloss:0.648851\tvalidation_1-mlogloss:0.714979\n",
      "[29]\tvalidation_0-mlogloss:0.637991\tvalidation_1-mlogloss:0.705527\n",
      "[30]\tvalidation_0-mlogloss:0.627384\tvalidation_1-mlogloss:0.696452\n",
      "[31]\tvalidation_0-mlogloss:0.617133\tvalidation_1-mlogloss:0.687892\n",
      "[32]\tvalidation_0-mlogloss:0.607338\tvalidation_1-mlogloss:0.679769\n",
      "[33]\tvalidation_0-mlogloss:0.598654\tvalidation_1-mlogloss:0.672178\n",
      "[34]\tvalidation_0-mlogloss:0.589934\tvalidation_1-mlogloss:0.665098\n",
      "[35]\tvalidation_0-mlogloss:0.581575\tvalidation_1-mlogloss:0.65844\n",
      "[36]\tvalidation_0-mlogloss:0.573562\tvalidation_1-mlogloss:0.652006\n",
      "[37]\tvalidation_0-mlogloss:0.566313\tvalidation_1-mlogloss:0.646205\n",
      "[38]\tvalidation_0-mlogloss:0.559431\tvalidation_1-mlogloss:0.640481\n",
      "[39]\tvalidation_0-mlogloss:0.553126\tvalidation_1-mlogloss:0.635303\n",
      "[40]\tvalidation_0-mlogloss:0.546485\tvalidation_1-mlogloss:0.6303\n",
      "[41]\tvalidation_0-mlogloss:0.539529\tvalidation_1-mlogloss:0.625073\n",
      "[42]\tvalidation_0-mlogloss:0.533583\tvalidation_1-mlogloss:0.62068\n",
      "[43]\tvalidation_0-mlogloss:0.528471\tvalidation_1-mlogloss:0.616677\n",
      "[44]\tvalidation_0-mlogloss:0.522784\tvalidation_1-mlogloss:0.612406\n",
      "[45]\tvalidation_0-mlogloss:0.517997\tvalidation_1-mlogloss:0.608387\n",
      "[46]\tvalidation_0-mlogloss:0.512989\tvalidation_1-mlogloss:0.604747\n",
      "[47]\tvalidation_0-mlogloss:0.50799\tvalidation_1-mlogloss:0.600866\n",
      "[48]\tvalidation_0-mlogloss:0.503133\tvalidation_1-mlogloss:0.597367\n",
      "[49]\tvalidation_0-mlogloss:0.498379\tvalidation_1-mlogloss:0.593899\n",
      "[50]\tvalidation_0-mlogloss:0.493737\tvalidation_1-mlogloss:0.590703\n",
      "[51]\tvalidation_0-mlogloss:0.48978\tvalidation_1-mlogloss:0.587748\n",
      "[52]\tvalidation_0-mlogloss:0.485419\tvalidation_1-mlogloss:0.58486\n",
      "[53]\tvalidation_0-mlogloss:0.481928\tvalidation_1-mlogloss:0.58226\n",
      "[54]\tvalidation_0-mlogloss:0.478182\tvalidation_1-mlogloss:0.579618\n",
      "[55]\tvalidation_0-mlogloss:0.474508\tvalidation_1-mlogloss:0.576929\n",
      "[56]\tvalidation_0-mlogloss:0.471074\tvalidation_1-mlogloss:0.574384\n",
      "[57]\tvalidation_0-mlogloss:0.467847\tvalidation_1-mlogloss:0.572185\n",
      "[58]\tvalidation_0-mlogloss:0.464778\tvalidation_1-mlogloss:0.569969\n",
      "[59]\tvalidation_0-mlogloss:0.461653\tvalidation_1-mlogloss:0.567587\n",
      "[60]\tvalidation_0-mlogloss:0.458843\tvalidation_1-mlogloss:0.565632\n",
      "[61]\tvalidation_0-mlogloss:0.455754\tvalidation_1-mlogloss:0.563622\n",
      "[62]\tvalidation_0-mlogloss:0.452868\tvalidation_1-mlogloss:0.561759\n",
      "[63]\tvalidation_0-mlogloss:0.450355\tvalidation_1-mlogloss:0.560092\n",
      "[64]\tvalidation_0-mlogloss:0.447836\tvalidation_1-mlogloss:0.558553\n",
      "[65]\tvalidation_0-mlogloss:0.445052\tvalidation_1-mlogloss:0.556743\n",
      "[66]\tvalidation_0-mlogloss:0.442719\tvalidation_1-mlogloss:0.55514\n",
      "[67]\tvalidation_0-mlogloss:0.440463\tvalidation_1-mlogloss:0.553689\n",
      "[68]\tvalidation_0-mlogloss:0.437717\tvalidation_1-mlogloss:0.551858\n",
      "[69]\tvalidation_0-mlogloss:0.435566\tvalidation_1-mlogloss:0.550537\n",
      "[70]\tvalidation_0-mlogloss:0.433003\tvalidation_1-mlogloss:0.549092\n",
      "[71]\tvalidation_0-mlogloss:0.430238\tvalidation_1-mlogloss:0.547425\n",
      "[72]\tvalidation_0-mlogloss:0.427561\tvalidation_1-mlogloss:0.545988\n",
      "[73]\tvalidation_0-mlogloss:0.425314\tvalidation_1-mlogloss:0.544709\n",
      "[74]\tvalidation_0-mlogloss:0.423164\tvalidation_1-mlogloss:0.543342\n",
      "[75]\tvalidation_0-mlogloss:0.420985\tvalidation_1-mlogloss:0.542175\n",
      "[76]\tvalidation_0-mlogloss:0.418954\tvalidation_1-mlogloss:0.541001\n",
      "[77]\tvalidation_0-mlogloss:0.416642\tvalidation_1-mlogloss:0.539593\n",
      "[78]\tvalidation_0-mlogloss:0.414166\tvalidation_1-mlogloss:0.538171\n",
      "[79]\tvalidation_0-mlogloss:0.412163\tvalidation_1-mlogloss:0.53706\n",
      "[80]\tvalidation_0-mlogloss:0.409317\tvalidation_1-mlogloss:0.535741\n",
      "[81]\tvalidation_0-mlogloss:0.407359\tvalidation_1-mlogloss:0.534601\n",
      "[82]\tvalidation_0-mlogloss:0.405451\tvalidation_1-mlogloss:0.533499\n",
      "[83]\tvalidation_0-mlogloss:0.403354\tvalidation_1-mlogloss:0.532393\n",
      "[84]\tvalidation_0-mlogloss:0.401508\tvalidation_1-mlogloss:0.53132\n",
      "[85]\tvalidation_0-mlogloss:0.399822\tvalidation_1-mlogloss:0.530388\n",
      "[86]\tvalidation_0-mlogloss:0.398305\tvalidation_1-mlogloss:0.529573\n",
      "[87]\tvalidation_0-mlogloss:0.396704\tvalidation_1-mlogloss:0.528665\n",
      "[88]\tvalidation_0-mlogloss:0.394622\tvalidation_1-mlogloss:0.527616\n",
      "[89]\tvalidation_0-mlogloss:0.392826\tvalidation_1-mlogloss:0.526689\n",
      "[90]\tvalidation_0-mlogloss:0.391008\tvalidation_1-mlogloss:0.525738\n",
      "[91]\tvalidation_0-mlogloss:0.389485\tvalidation_1-mlogloss:0.525012\n",
      "[92]\tvalidation_0-mlogloss:0.3879\tvalidation_1-mlogloss:0.524363\n",
      "[93]\tvalidation_0-mlogloss:0.386205\tvalidation_1-mlogloss:0.523407\n",
      "[94]\tvalidation_0-mlogloss:0.384812\tvalidation_1-mlogloss:0.522684\n",
      "[95]\tvalidation_0-mlogloss:0.383092\tvalidation_1-mlogloss:0.521766\n",
      "[96]\tvalidation_0-mlogloss:0.381565\tvalidation_1-mlogloss:0.520891\n",
      "[97]\tvalidation_0-mlogloss:0.379977\tvalidation_1-mlogloss:0.520257\n",
      "[98]\tvalidation_0-mlogloss:0.378665\tvalidation_1-mlogloss:0.519577\n",
      "[99]\tvalidation_0-mlogloss:0.377122\tvalidation_1-mlogloss:0.518703\n"
     ]
    }
   ],
   "source": [
    "###########################modeling###########################\n",
    "\n",
    "#xgboost\n",
    "\n",
    "print(\" - Running xgboost.\")\n",
    "param = {}\n",
    "param['eval_metric'] = 'mlogloss'\n",
    "param['objective'] = 'reg:linear'\n",
    "param['subsample'] = 0.8\n",
    "param['colsample_bytree'] = 0.8\n",
    "param['silent'] = 1\n",
    "param['max_depth'] = 7\n",
    "param['n_estimators']=100\n",
    "    \n",
    "dtrain = xgb.DMatrix(X_train, label = y_train)  \n",
    "my_model = xgb.XGBClassifier(**param)\n",
    "\n",
    "clf = my_model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='mlogloss') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      " -- Multiclass logloss on xgboost validation set: 0.5187.\n"
     ]
    }
   ],
   "source": [
    "evals_result = clf.evals_result()\n",
    "print (np.argmax(evals_result['validation_1']['mlogloss']))\n",
    "\n",
    "my_model = my_model.set_params(n_estimators = np.argmax(evals_result['validation_1']['mlogloss']))\n",
    "\n",
    "y_pred = my_model.predict_proba(X_valid)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_true = encoder.fit_transform(y_valid)\n",
    "score = logloss_mc(y_true, y_pred)\n",
    "print(\" -- Multiclass logloss on xgboost validation set: {:.4f}.\".format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - XGB Finished.\n"
     ]
    }
   ],
   "source": [
    "###########################result calculation###########################\n",
    "\n",
    "test_predictions = clf.predict_proba(X_TST)\n",
    "\n",
    "#output result\n",
    "output = pd.DataFrame(test_predictions)\n",
    "\n",
    "output.columns = ['c1', 'c2', 'c3', 'c4','c5','c6','c7','c8','c9']\n",
    "output.to_csv('SK_submission_xgb.csv', index = False)\n",
    "\n",
    "print(\" - XGB Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Preparing lightgbm\n"
     ]
    }
   ],
   "source": [
    "#lightgbm\n",
    "#try lightgbm\n",
    "\n",
    "print (\" - Preparing lightgbm\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "def fit_predict(data, y, test, test_sub):\n",
    "    dtrain = lgb.Dataset(data=data, label=y, free_raw_data=False)\n",
    "    dtrain.construct()\n",
    "    \n",
    "    #oof_preds = np.zeros((data.shape[0],9))\n",
    "    test_preds = np.zeros((test.shape[0],9))\n",
    "    test_sub_preds = np.zeros((test_sub.shape[0],9))\n",
    "    \n",
    "    lgb_params = {\n",
    "        \"objective\" : \"multiclass\",\n",
    "        \"num_class\" : 9,\n",
    "        \"metric\" : \"multi_logloss\",\n",
    "        \"num_leaves\": 5,\n",
    "        \"min_data_in_leaf\": 5,\n",
    "        \"learning_rate\": 0.01,\n",
    "\n",
    "        \"feature_fraction\": 1,\n",
    "        \"feature_fraction_seed\": 2,\n",
    "\n",
    "   #     \"bagging_fraction\": 0.8,\n",
    "   #     \"bagging_freq\" : 10,\n",
    "   #     \"bagging_seed\" : 42, #2018\n",
    "\n",
    "        \"verbosity\" : 1,\n",
    "#         'lambda_l1' : 10,\n",
    "#         'lambda_l2' : 10,\n",
    "#        'max_bin' : 50\n",
    "    }\n",
    "\n",
    "    folds = KFold(n_splits=2, shuffle=True, random_state=2)\n",
    "\n",
    "    counter = 1\n",
    "    for trn_idx, val_idx in folds.split(data):\n",
    "        print('----------------------------')\n",
    "        print('Fold: %d' % counter)\n",
    "\n",
    "        trn_d = dtrain.subset(trn_idx)\n",
    "        val_d = dtrain.subset(val_idx)\n",
    "\n",
    "        clf = lgb.train(\n",
    "            params=lgb_params,\n",
    "            train_set=trn_d,\n",
    "            valid_sets=[trn_d, val_d],\n",
    "            num_boost_round=5000,\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=50\n",
    "        )\n",
    "\n",
    "\n",
    "        #oof_preds[val_idx] = clf.predict(dtrain.data[val_idx, :])\n",
    "        test_preds += clf.predict(test) / folds.n_splits\n",
    "        test_sub_preds += clf.predict(test_sub) / folds.n_splits\n",
    "        \n",
    "        counter += 1\n",
    "\n",
    "    return test_preds , test_sub_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - LightGBM is Running.\n",
      "----------------------------\n",
      "Fold: 1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's multi_logloss: 1.62801\tvalid_1's multi_logloss: 1.63036\n",
      "[100]\ttraining's multi_logloss: 1.35386\tvalid_1's multi_logloss: 1.35907\n",
      "[150]\ttraining's multi_logloss: 1.18521\tvalid_1's multi_logloss: 1.19207\n",
      "[200]\ttraining's multi_logloss: 1.07044\tvalid_1's multi_logloss: 1.079\n",
      "[250]\ttraining's multi_logloss: 0.985587\tvalid_1's multi_logloss: 0.995872\n",
      "[300]\ttraining's multi_logloss: 0.923244\tvalid_1's multi_logloss: 0.934945\n",
      "[350]\ttraining's multi_logloss: 0.875759\tvalid_1's multi_logloss: 0.888697\n",
      "[400]\ttraining's multi_logloss: 0.837948\tvalid_1's multi_logloss: 0.851899\n",
      "[450]\ttraining's multi_logloss: 0.807021\tvalid_1's multi_logloss: 0.821928\n",
      "[500]\ttraining's multi_logloss: 0.781095\tvalid_1's multi_logloss: 0.796949\n",
      "[550]\ttraining's multi_logloss: 0.75908\tvalid_1's multi_logloss: 0.776008\n",
      "[600]\ttraining's multi_logloss: 0.740001\tvalid_1's multi_logloss: 0.758157\n",
      "[650]\ttraining's multi_logloss: 0.723418\tvalid_1's multi_logloss: 0.742652\n",
      "[700]\ttraining's multi_logloss: 0.708959\tvalid_1's multi_logloss: 0.729175\n",
      "[750]\ttraining's multi_logloss: 0.695984\tvalid_1's multi_logloss: 0.717364\n",
      "[800]\ttraining's multi_logloss: 0.684231\tvalid_1's multi_logloss: 0.70691\n",
      "[850]\ttraining's multi_logloss: 0.673691\tvalid_1's multi_logloss: 0.697698\n",
      "[900]\ttraining's multi_logloss: 0.664035\tvalid_1's multi_logloss: 0.689437\n",
      "[950]\ttraining's multi_logloss: 0.655261\tvalid_1's multi_logloss: 0.682013\n",
      "[1000]\ttraining's multi_logloss: 0.647133\tvalid_1's multi_logloss: 0.675069\n",
      "[1050]\ttraining's multi_logloss: 0.639695\tvalid_1's multi_logloss: 0.668764\n",
      "[1100]\ttraining's multi_logloss: 0.632673\tvalid_1's multi_logloss: 0.662939\n",
      "[1150]\ttraining's multi_logloss: 0.626091\tvalid_1's multi_logloss: 0.657552\n",
      "[1200]\ttraining's multi_logloss: 0.61999\tvalid_1's multi_logloss: 0.652519\n",
      "[1250]\ttraining's multi_logloss: 0.614255\tvalid_1's multi_logloss: 0.647949\n",
      "[1300]\ttraining's multi_logloss: 0.608856\tvalid_1's multi_logloss: 0.643697\n",
      "[1350]\ttraining's multi_logloss: 0.603742\tvalid_1's multi_logloss: 0.639634\n",
      "[1400]\ttraining's multi_logloss: 0.598847\tvalid_1's multi_logloss: 0.635997\n",
      "[1450]\ttraining's multi_logloss: 0.594198\tvalid_1's multi_logloss: 0.632566\n",
      "[1500]\ttraining's multi_logloss: 0.58977\tvalid_1's multi_logloss: 0.629308\n",
      "[1550]\ttraining's multi_logloss: 0.585525\tvalid_1's multi_logloss: 0.62629\n",
      "[1600]\ttraining's multi_logloss: 0.581466\tvalid_1's multi_logloss: 0.623402\n",
      "[1650]\ttraining's multi_logloss: 0.577551\tvalid_1's multi_logloss: 0.620696\n",
      "[1700]\ttraining's multi_logloss: 0.573781\tvalid_1's multi_logloss: 0.618177\n",
      "[1750]\ttraining's multi_logloss: 0.570106\tvalid_1's multi_logloss: 0.615787\n",
      "[1800]\ttraining's multi_logloss: 0.566604\tvalid_1's multi_logloss: 0.613472\n",
      "[1850]\ttraining's multi_logloss: 0.563203\tvalid_1's multi_logloss: 0.611371\n",
      "[1900]\ttraining's multi_logloss: 0.559918\tvalid_1's multi_logloss: 0.609295\n",
      "[1950]\ttraining's multi_logloss: 0.556745\tvalid_1's multi_logloss: 0.607288\n",
      "[2000]\ttraining's multi_logloss: 0.553614\tvalid_1's multi_logloss: 0.605296\n",
      "[2050]\ttraining's multi_logloss: 0.550576\tvalid_1's multi_logloss: 0.603381\n",
      "[2100]\ttraining's multi_logloss: 0.547625\tvalid_1's multi_logloss: 0.601546\n",
      "[2150]\ttraining's multi_logloss: 0.544746\tvalid_1's multi_logloss: 0.599757\n",
      "[2200]\ttraining's multi_logloss: 0.541906\tvalid_1's multi_logloss: 0.598041\n",
      "[2250]\ttraining's multi_logloss: 0.539176\tvalid_1's multi_logloss: 0.596466\n",
      "[2300]\ttraining's multi_logloss: 0.536539\tvalid_1's multi_logloss: 0.594933\n",
      "[2350]\ttraining's multi_logloss: 0.533935\tvalid_1's multi_logloss: 0.593452\n",
      "[2400]\ttraining's multi_logloss: 0.531434\tvalid_1's multi_logloss: 0.592049\n",
      "[2450]\ttraining's multi_logloss: 0.528947\tvalid_1's multi_logloss: 0.590672\n",
      "[2500]\ttraining's multi_logloss: 0.526511\tvalid_1's multi_logloss: 0.589361\n",
      "[2550]\ttraining's multi_logloss: 0.524141\tvalid_1's multi_logloss: 0.588077\n",
      "[2600]\ttraining's multi_logloss: 0.521809\tvalid_1's multi_logloss: 0.586832\n",
      "[2650]\ttraining's multi_logloss: 0.519516\tvalid_1's multi_logloss: 0.585593\n",
      "[2700]\ttraining's multi_logloss: 0.51724\tvalid_1's multi_logloss: 0.584443\n",
      "[2750]\ttraining's multi_logloss: 0.51502\tvalid_1's multi_logloss: 0.583274\n",
      "[2800]\ttraining's multi_logloss: 0.512857\tvalid_1's multi_logloss: 0.582156\n",
      "[2850]\ttraining's multi_logloss: 0.510691\tvalid_1's multi_logloss: 0.581055\n",
      "[2900]\ttraining's multi_logloss: 0.50859\tvalid_1's multi_logloss: 0.580047\n",
      "[2950]\ttraining's multi_logloss: 0.506504\tvalid_1's multi_logloss: 0.57906\n",
      "[3000]\ttraining's multi_logloss: 0.504461\tvalid_1's multi_logloss: 0.578037\n",
      "[3050]\ttraining's multi_logloss: 0.50247\tvalid_1's multi_logloss: 0.577096\n",
      "[3100]\ttraining's multi_logloss: 0.500491\tvalid_1's multi_logloss: 0.576166\n",
      "[3150]\ttraining's multi_logloss: 0.498556\tvalid_1's multi_logloss: 0.575252\n",
      "[3200]\ttraining's multi_logloss: 0.496622\tvalid_1's multi_logloss: 0.574355\n",
      "[3250]\ttraining's multi_logloss: 0.494742\tvalid_1's multi_logloss: 0.573501\n",
      "[3300]\ttraining's multi_logloss: 0.492911\tvalid_1's multi_logloss: 0.572657\n",
      "[3350]\ttraining's multi_logloss: 0.491098\tvalid_1's multi_logloss: 0.571796\n",
      "[3400]\ttraining's multi_logloss: 0.489287\tvalid_1's multi_logloss: 0.571007\n",
      "[3450]\ttraining's multi_logloss: 0.487524\tvalid_1's multi_logloss: 0.570206\n",
      "[3500]\ttraining's multi_logloss: 0.485764\tvalid_1's multi_logloss: 0.569484\n",
      "[3550]\ttraining's multi_logloss: 0.484037\tvalid_1's multi_logloss: 0.568725\n",
      "[3600]\ttraining's multi_logloss: 0.482307\tvalid_1's multi_logloss: 0.567944\n",
      "[3650]\ttraining's multi_logloss: 0.480633\tvalid_1's multi_logloss: 0.567251\n",
      "[3700]\ttraining's multi_logloss: 0.478964\tvalid_1's multi_logloss: 0.566544\n",
      "[3750]\ttraining's multi_logloss: 0.477325\tvalid_1's multi_logloss: 0.565861\n",
      "[3800]\ttraining's multi_logloss: 0.475707\tvalid_1's multi_logloss: 0.565176\n",
      "[3850]\ttraining's multi_logloss: 0.474121\tvalid_1's multi_logloss: 0.564533\n",
      "[3900]\ttraining's multi_logloss: 0.472557\tvalid_1's multi_logloss: 0.563888\n",
      "[3950]\ttraining's multi_logloss: 0.470994\tvalid_1's multi_logloss: 0.563254\n",
      "[4000]\ttraining's multi_logloss: 0.469449\tvalid_1's multi_logloss: 0.562625\n",
      "[4050]\ttraining's multi_logloss: 0.467946\tvalid_1's multi_logloss: 0.562017\n",
      "[4100]\ttraining's multi_logloss: 0.466443\tvalid_1's multi_logloss: 0.561411\n",
      "[4150]\ttraining's multi_logloss: 0.464942\tvalid_1's multi_logloss: 0.560807\n",
      "[4200]\ttraining's multi_logloss: 0.463471\tvalid_1's multi_logloss: 0.560244\n",
      "[4250]\ttraining's multi_logloss: 0.462024\tvalid_1's multi_logloss: 0.559695\n",
      "[4300]\ttraining's multi_logloss: 0.460575\tvalid_1's multi_logloss: 0.559139\n",
      "[4350]\ttraining's multi_logloss: 0.459148\tvalid_1's multi_logloss: 0.558582\n",
      "[4400]\ttraining's multi_logloss: 0.457739\tvalid_1's multi_logloss: 0.558074\n",
      "[4450]\ttraining's multi_logloss: 0.456325\tvalid_1's multi_logloss: 0.557542\n",
      "[4500]\ttraining's multi_logloss: 0.454914\tvalid_1's multi_logloss: 0.556993\n",
      "[4550]\ttraining's multi_logloss: 0.453535\tvalid_1's multi_logloss: 0.556454\n",
      "[4600]\ttraining's multi_logloss: 0.452146\tvalid_1's multi_logloss: 0.555951\n",
      "[4650]\ttraining's multi_logloss: 0.450795\tvalid_1's multi_logloss: 0.555446\n",
      "[4700]\ttraining's multi_logloss: 0.449442\tvalid_1's multi_logloss: 0.554951\n",
      "[4750]\ttraining's multi_logloss: 0.448095\tvalid_1's multi_logloss: 0.554446\n",
      "[4800]\ttraining's multi_logloss: 0.44676\tvalid_1's multi_logloss: 0.55399\n",
      "[4850]\ttraining's multi_logloss: 0.445459\tvalid_1's multi_logloss: 0.553497\n",
      "[4900]\ttraining's multi_logloss: 0.444117\tvalid_1's multi_logloss: 0.553048\n",
      "[4950]\ttraining's multi_logloss: 0.442825\tvalid_1's multi_logloss: 0.552623\n",
      "[5000]\ttraining's multi_logloss: 0.44156\tvalid_1's multi_logloss: 0.552147\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's multi_logloss: 0.44156\tvalid_1's multi_logloss: 0.552147\n",
      "----------------------------\n",
      "Fold: 2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's multi_logloss: 1.62358\tvalid_1's multi_logloss: 1.62782\n",
      "[100]\ttraining's multi_logloss: 1.35077\tvalid_1's multi_logloss: 1.35616\n",
      "[150]\ttraining's multi_logloss: 1.18204\tvalid_1's multi_logloss: 1.18887\n",
      "[200]\ttraining's multi_logloss: 1.06527\tvalid_1's multi_logloss: 1.07331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\ttraining's multi_logloss: 0.981559\tvalid_1's multi_logloss: 0.991138\n",
      "[300]\ttraining's multi_logloss: 0.920085\tvalid_1's multi_logloss: 0.930947\n",
      "[350]\ttraining's multi_logloss: 0.872609\tvalid_1's multi_logloss: 0.884998\n",
      "[400]\ttraining's multi_logloss: 0.834685\tvalid_1's multi_logloss: 0.848692\n",
      "[450]\ttraining's multi_logloss: 0.803574\tvalid_1's multi_logloss: 0.81922\n",
      "[500]\ttraining's multi_logloss: 0.777681\tvalid_1's multi_logloss: 0.794821\n",
      "[550]\ttraining's multi_logloss: 0.75569\tvalid_1's multi_logloss: 0.774216\n",
      "[600]\ttraining's multi_logloss: 0.736464\tvalid_1's multi_logloss: 0.756288\n",
      "[650]\ttraining's multi_logloss: 0.71982\tvalid_1's multi_logloss: 0.741009\n",
      "[700]\ttraining's multi_logloss: 0.70515\tvalid_1's multi_logloss: 0.727691\n",
      "[750]\ttraining's multi_logloss: 0.692075\tvalid_1's multi_logloss: 0.71593\n",
      "[800]\ttraining's multi_logloss: 0.680363\tvalid_1's multi_logloss: 0.705649\n",
      "[850]\ttraining's multi_logloss: 0.669844\tvalid_1's multi_logloss: 0.696422\n",
      "[900]\ttraining's multi_logloss: 0.660272\tvalid_1's multi_logloss: 0.68813\n",
      "[950]\ttraining's multi_logloss: 0.65155\tvalid_1's multi_logloss: 0.680647\n",
      "[1000]\ttraining's multi_logloss: 0.643472\tvalid_1's multi_logloss: 0.673769\n",
      "[1050]\ttraining's multi_logloss: 0.636045\tvalid_1's multi_logloss: 0.667611\n",
      "[1100]\ttraining's multi_logloss: 0.629164\tvalid_1's multi_logloss: 0.661977\n",
      "[1150]\ttraining's multi_logloss: 0.622702\tvalid_1's multi_logloss: 0.65678\n",
      "[1200]\ttraining's multi_logloss: 0.616614\tvalid_1's multi_logloss: 0.651949\n",
      "[1250]\ttraining's multi_logloss: 0.610882\tvalid_1's multi_logloss: 0.647514\n",
      "[1300]\ttraining's multi_logloss: 0.605409\tvalid_1's multi_logloss: 0.643309\n",
      "[1350]\ttraining's multi_logloss: 0.60028\tvalid_1's multi_logloss: 0.639417\n",
      "[1400]\ttraining's multi_logloss: 0.59536\tvalid_1's multi_logloss: 0.635766\n",
      "[1450]\ttraining's multi_logloss: 0.59058\tvalid_1's multi_logloss: 0.632219\n",
      "[1500]\ttraining's multi_logloss: 0.586114\tvalid_1's multi_logloss: 0.629023\n",
      "[1550]\ttraining's multi_logloss: 0.58181\tvalid_1's multi_logloss: 0.625968\n",
      "[1600]\ttraining's multi_logloss: 0.577689\tvalid_1's multi_logloss: 0.623156\n",
      "[1650]\ttraining's multi_logloss: 0.573797\tvalid_1's multi_logloss: 0.62047\n",
      "[1700]\ttraining's multi_logloss: 0.569987\tvalid_1's multi_logloss: 0.617952\n",
      "[1750]\ttraining's multi_logloss: 0.566277\tvalid_1's multi_logloss: 0.615539\n",
      "[1800]\ttraining's multi_logloss: 0.562717\tvalid_1's multi_logloss: 0.613323\n",
      "[1850]\ttraining's multi_logloss: 0.559319\tvalid_1's multi_logloss: 0.611166\n",
      "[1900]\ttraining's multi_logloss: 0.556039\tvalid_1's multi_logloss: 0.609078\n",
      "[1950]\ttraining's multi_logloss: 0.552809\tvalid_1's multi_logloss: 0.607046\n",
      "[2000]\ttraining's multi_logloss: 0.549723\tvalid_1's multi_logloss: 0.605142\n",
      "[2050]\ttraining's multi_logloss: 0.54664\tvalid_1's multi_logloss: 0.603327\n",
      "[2100]\ttraining's multi_logloss: 0.543682\tvalid_1's multi_logloss: 0.601566\n",
      "[2150]\ttraining's multi_logloss: 0.54084\tvalid_1's multi_logloss: 0.599891\n",
      "[2200]\ttraining's multi_logloss: 0.53805\tvalid_1's multi_logloss: 0.598235\n",
      "[2250]\ttraining's multi_logloss: 0.535358\tvalid_1's multi_logloss: 0.596706\n",
      "[2300]\ttraining's multi_logloss: 0.532742\tvalid_1's multi_logloss: 0.595293\n",
      "[2350]\ttraining's multi_logloss: 0.530182\tvalid_1's multi_logloss: 0.593929\n",
      "[2400]\ttraining's multi_logloss: 0.527685\tvalid_1's multi_logloss: 0.592558\n",
      "[2450]\ttraining's multi_logloss: 0.52515\tvalid_1's multi_logloss: 0.591197\n",
      "[2500]\ttraining's multi_logloss: 0.52271\tvalid_1's multi_logloss: 0.589911\n",
      "[2550]\ttraining's multi_logloss: 0.520363\tvalid_1's multi_logloss: 0.588742\n",
      "[2600]\ttraining's multi_logloss: 0.518024\tvalid_1's multi_logloss: 0.587543\n",
      "[2650]\ttraining's multi_logloss: 0.515726\tvalid_1's multi_logloss: 0.586442\n",
      "[2700]\ttraining's multi_logloss: 0.513419\tvalid_1's multi_logloss: 0.58535\n",
      "[2750]\ttraining's multi_logloss: 0.511227\tvalid_1's multi_logloss: 0.584297\n",
      "[2800]\ttraining's multi_logloss: 0.509049\tvalid_1's multi_logloss: 0.583263\n",
      "[2850]\ttraining's multi_logloss: 0.506912\tvalid_1's multi_logloss: 0.582225\n",
      "[2900]\ttraining's multi_logloss: 0.50481\tvalid_1's multi_logloss: 0.58119\n",
      "[2950]\ttraining's multi_logloss: 0.50276\tvalid_1's multi_logloss: 0.580204\n",
      "[3000]\ttraining's multi_logloss: 0.500734\tvalid_1's multi_logloss: 0.579295\n",
      "[3050]\ttraining's multi_logloss: 0.498763\tvalid_1's multi_logloss: 0.578391\n",
      "[3100]\ttraining's multi_logloss: 0.496787\tvalid_1's multi_logloss: 0.577499\n",
      "[3150]\ttraining's multi_logloss: 0.494879\tvalid_1's multi_logloss: 0.576623\n",
      "[3200]\ttraining's multi_logloss: 0.492983\tvalid_1's multi_logloss: 0.575769\n",
      "[3250]\ttraining's multi_logloss: 0.491102\tvalid_1's multi_logloss: 0.574949\n",
      "[3300]\ttraining's multi_logloss: 0.489247\tvalid_1's multi_logloss: 0.574154\n",
      "[3350]\ttraining's multi_logloss: 0.487447\tvalid_1's multi_logloss: 0.573383\n",
      "[3400]\ttraining's multi_logloss: 0.485655\tvalid_1's multi_logloss: 0.572607\n",
      "[3450]\ttraining's multi_logloss: 0.483899\tvalid_1's multi_logloss: 0.57186\n",
      "[3500]\ttraining's multi_logloss: 0.48217\tvalid_1's multi_logloss: 0.571157\n",
      "[3550]\ttraining's multi_logloss: 0.480476\tvalid_1's multi_logloss: 0.570404\n",
      "[3600]\ttraining's multi_logloss: 0.478771\tvalid_1's multi_logloss: 0.569678\n",
      "[3650]\ttraining's multi_logloss: 0.477111\tvalid_1's multi_logloss: 0.569021\n",
      "[3700]\ttraining's multi_logloss: 0.475457\tvalid_1's multi_logloss: 0.568342\n",
      "[3750]\ttraining's multi_logloss: 0.473815\tvalid_1's multi_logloss: 0.567679\n",
      "[3800]\ttraining's multi_logloss: 0.472226\tvalid_1's multi_logloss: 0.567064\n",
      "[3850]\ttraining's multi_logloss: 0.470662\tvalid_1's multi_logloss: 0.56643\n",
      "[3900]\ttraining's multi_logloss: 0.469108\tvalid_1's multi_logloss: 0.56582\n",
      "[3950]\ttraining's multi_logloss: 0.46759\tvalid_1's multi_logloss: 0.56524\n",
      "[4000]\ttraining's multi_logloss: 0.466062\tvalid_1's multi_logloss: 0.564621\n",
      "[4050]\ttraining's multi_logloss: 0.464546\tvalid_1's multi_logloss: 0.564046\n",
      "[4100]\ttraining's multi_logloss: 0.463063\tvalid_1's multi_logloss: 0.563478\n",
      "[4150]\ttraining's multi_logloss: 0.461609\tvalid_1's multi_logloss: 0.562887\n",
      "[4200]\ttraining's multi_logloss: 0.460153\tvalid_1's multi_logloss: 0.562328\n",
      "[4250]\ttraining's multi_logloss: 0.458674\tvalid_1's multi_logloss: 0.561774\n",
      "[4300]\ttraining's multi_logloss: 0.457235\tvalid_1's multi_logloss: 0.561253\n",
      "[4350]\ttraining's multi_logloss: 0.455803\tvalid_1's multi_logloss: 0.560706\n",
      "[4400]\ttraining's multi_logloss: 0.454371\tvalid_1's multi_logloss: 0.560185\n",
      "[4450]\ttraining's multi_logloss: 0.452996\tvalid_1's multi_logloss: 0.55971\n",
      "[4500]\ttraining's multi_logloss: 0.451627\tvalid_1's multi_logloss: 0.559247\n",
      "[4550]\ttraining's multi_logloss: 0.450267\tvalid_1's multi_logloss: 0.558769\n",
      "[4600]\ttraining's multi_logloss: 0.448921\tvalid_1's multi_logloss: 0.558277\n",
      "[4650]\ttraining's multi_logloss: 0.447592\tvalid_1's multi_logloss: 0.557847\n",
      "[4700]\ttraining's multi_logloss: 0.446242\tvalid_1's multi_logloss: 0.557383\n",
      "[4750]\ttraining's multi_logloss: 0.444935\tvalid_1's multi_logloss: 0.556965\n",
      "[4800]\ttraining's multi_logloss: 0.443635\tvalid_1's multi_logloss: 0.556496\n",
      "[4850]\ttraining's multi_logloss: 0.442367\tvalid_1's multi_logloss: 0.556084\n",
      "[4900]\ttraining's multi_logloss: 0.441097\tvalid_1's multi_logloss: 0.555664\n",
      "[4950]\ttraining's multi_logloss: 0.439859\tvalid_1's multi_logloss: 0.555252\n",
      "[5000]\ttraining's multi_logloss: 0.43859\tvalid_1's multi_logloss: 0.554862\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's multi_logloss: 0.43859\tvalid_1's multi_logloss: 0.554862\n",
      " - LightGBM Finished.\n"
     ]
    }
   ],
   "source": [
    "y_train_class_0_8 = y_train-np.ones(y_train.shape)\n",
    "print(\" - LightGBM is Running.\")\n",
    "y_predict, test_predict = fit_predict(X_train, y_train_class_0_8, X_valid, X_TST)\n",
    "print(\" - LightGBM Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Multiclass logloss on xgboost and lgb validation set: 0.5237.\n"
     ]
    }
   ],
   "source": [
    "y_prediction_xgb_and_lgb= (y_predict + y_pred) / 2\n",
    "\n",
    "score = logloss_mc(y_true, y_prediction_xgb_and_lgb)\n",
    "\n",
    "print(\" -- Multiclass logloss on xgboost and lgb validation set: {:.4f}.\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - XGB and LGB are Finished.\n"
     ]
    }
   ],
   "source": [
    "test_prediction_xgb_and_lgb= (test_predictions + test_predict) / 2\n",
    "#output result\n",
    "output = pd.DataFrame(test_prediction_xgb_and_lgb)\n",
    "output.columns = ['c1', 'c2', 'c3', 'c4','c5','c6','c7','c8','c9']\n",
    "output.to_csv('SK_submission_xgb_lgb.csv', index = False)\n",
    "\n",
    "print(\" - XGB and LGB are Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
